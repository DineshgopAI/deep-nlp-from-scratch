{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0657a8b3-331e-451d-a65a-1478e57abe72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe91d8-9902-4be6-8659-2d406bffd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cda40-0d09-4650-9176-debfb08836e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5293155-a755-457e-8567-dd11fd45f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ji\n"
     ]
    }
   ],
   "source": [
    "print(\"ji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bab055d-26e5-421e-b7a9-20ae634a03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in b:\\deep_nlp_project\\venv_nlp\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 13.0 MB/s eta 0:00:00\n",
      "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 15.5 MB/s eta 0:00:00\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: pillow, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ---------------------------------------- 0/6 [pillow]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------ --------------------------------- 1/6 [fsspec]\n",
      "   ------------- -------------------------- 2/6 [filelock]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   -------------------------- ------------- 4/6 [torchvision]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   --------------------------------- ------ 5/6 [torchaudio]\n",
      "   ---------------------------------------- 6/6 [torchaudio]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 pillow-11.2.1 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3611553f-6b72-4907-ba82-5ff138dc8c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.7.1+cpu\n",
      "CUDA avaiable (GPU support): False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Pytorch version:\", torch.__version__)\n",
    "print(\"CUDA avaiable (GPU support):\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d4a027-0f9f-45b9-8f9c-fb21e88f3273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Creating Tensors--\n",
      "\n",
      "1D Tensor (vector):\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "Shape: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np #we will use numpy to show conversions\n",
    "\n",
    "print(\"--Creating Tensors--\")\n",
    "#Creating a Tensor from a Python List\n",
    "# A 1D tensor(vector)\n",
    "tensor_1d=torch.tensor([1,2,3,4,5])\n",
    "print(\"\\n1D Tensor (vector):\")\n",
    "print(tensor_1d)\n",
    "print(\"Shape:\", tensor_1d.shape) #How many elements are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e9e53b-793b-4246-b069-a3273c0b1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D Tensor (Matrix):\n",
      "tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "Shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# A 2D tensor (matrix)\n",
    "tensor_2d= torch.tensor([[10,20,30],[40,50,60]])\n",
    "print(\"\\n2D Tensor (Matrix):\")\n",
    "print(tensor_2d)\n",
    "print(\"Shape:\", tensor_2d.shape) #what does (2,3) mean?(rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f42b486-b164-459d-81cc-9f88682f6ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor from Numpy Array:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. Creating a tensor from a Numpy array\n",
    "numpy_array=np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "tensor_from_numpy=torch.from_numpy(numpy_array)\n",
    "print(\"\\n Tensor from Numpy Array:\")\n",
    "print(tensor_from_numpy)\n",
    "print(\"Shape:\", tensor_from_numpy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d98bc43-0bd9-47c4-b113-107cfed21091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array after change: [[99  2  3]\n",
      " [ 4  5  6]]\n",
      "Tensor from Numpy after change: tensor([[99,  2,  3],\n",
      "        [ 4,  5,  6]])\n"
     ]
    }
   ],
   "source": [
    "# Note: Changes in the Numpy array will affect the tensor and vice versa (they share memory).\n",
    "numpy_array[0,0]=99\n",
    "print(\"Numpy array after change:\",numpy_array)\n",
    "print(\"Tensor from Numpy after change:\", tensor_from_numpy) # See the change reflected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c7a32f-667f-47b3-92bf-099c5541ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zeros Tensor (2x3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#Creating tensors of zero, ones, or random values\n",
    "#All Zeors (2 rows, 3 columns)\n",
    "\n",
    "zeros_tensor = torch.zeros(2,3)\n",
    "print(\"\\nZeros Tensor (2x3):\")\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f061e1-43fa-4eda-9c4b-e52c066eb4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ones Tensor (3x2):\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#All ones (3 rows, 2 columns)\n",
    "ones_tensor =torch.ones(3,2)\n",
    "print(\"\\nOnes Tensor (3x2):\")\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6128015f-d64a-480d-8447-4eb8655222fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Normal Tensor (2x3):\n",
      "tensor([[-1.5399,  0.9304, -0.5656],\n",
      "        [ 0.0751, -0.7791,  0.1889]])\n"
     ]
    }
   ],
   "source": [
    "# Random tensor with values between 0 and 1 (uniform distribution)\n",
    "random_tensor =torch.randn(2,3)\n",
    "print(\"\\nRandom Normal Tensor (2x3):\")\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bd31459-7fe1-4483-9a72-444b8d1b66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integer Tensor (int32): tensor([1, 2, 3], dtype=torch.int32) torch.int32\n"
     ]
    }
   ],
   "source": [
    "# 4. Creating tensors with specific data types (dtype)\n",
    "#By default, PyTorch infers data types, but you can specify them.\n",
    "\n",
    "int_tensor=torch.tensor([1,2,3], dtype=torch.int32)\n",
    "print(\"\\nInteger Tensor (int32):\", int_tensor, int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20cbd26e-1ed9-42a6-826f-77877c7aa6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float Tensor (float64): tensor([[0., 0.],\n",
      "        [0., 0.]], dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "float_tensor=torch.zeros(2,2, dtype=torch.float64) #Float64 is like Python's float\n",
    "print(\"Float Tensor (float64):\", float_tensor, float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5cd6b97-0392-4a6d-a706-39303b0ab240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2866, -0.1414,  1.3043,  0.9055],\n",
      "         [ 2.0557, -0.2497, -0.0369, -1.0538],\n",
      "         [ 1.1613,  0.8242, -1.0197,  0.4510]],\n",
      "\n",
      "        [[-0.0290, -1.3981, -0.5839,  0.2034],\n",
      "         [-1.3309,  0.2953,  0.0097,  0.6668],\n",
      "         [ 2.5723, -0.4506,  0.3268, -1.3866]]]) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Trying to create a 3D tensor with random values\n",
    "D_tensor= torch.randn(2,3,4)\n",
    "print(D_tensor,D_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a105af2f-ae9f-4270-b733-2fd2bd9bb359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor A:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Tensor B:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "\n",
      "Element-wise Addition (A+B):\n",
      " tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "\n",
      "Element-wise Multiplication (A*B):\n",
      " tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "\n",
      "Element-wise Divison (A/B):\n",
      " tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "\n",
      "Scalar Multiplication (A*2):\n",
      " tensor([[2, 4],\n",
      "        [6, 8]])\n",
      "Scalar Addition (A+10):\n",
      " tensor([[11, 12],\n",
      "        [13, 14]])\n",
      "\n",
      "Matrix 1:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Matrix 2:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "Matrix Multiplication (matrix1 @ matrix2):\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "Matrix Multiplication (torch.matmul(matrix1, matrix2):\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor Operations\n",
    "# 1. Basic Arithmetic Operations (Element-wise)\n",
    "\n",
    "tensor_a=torch.tensor([[1,2],[3,4]])\n",
    "tensor_b=torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "print(\"\\nTensor A:\\n\", tensor_a)\n",
    "print(\"\\nTensor B:\\n\", tensor_b)\n",
    "\n",
    "print(\"\\nElement-wise Addition (A+B):\\n\", tensor_a+tensor_b)\n",
    "print(\"\\nElement-wise Multiplication (A*B):\\n\", tensor_a*tensor_b)\n",
    "print(\"\\nElement-wise Divison (A/B):\\n\", tensor_a/tensor_b) #Note: Will convert to float if not already.\n",
    "\n",
    "# Scalar operations\n",
    "print(\"\\nScalar Multiplication (A*2):\\n\", tensor_a*2)\n",
    "print(\"Scalar Addition (A+10):\\n\", tensor_a+10)\n",
    "\n",
    "\n",
    "# 2. Matrix Multiplication (Dot Product)\n",
    "# This is fundamental for neural networks!\n",
    "# Remember the rule: (m x n) @ (n x p) = (m x p)\n",
    "\n",
    "matrix1= torch.tensor([[1,2],[3,4]]) #Shape (2,2)\n",
    "matrix2= torch.tensor([[5,6],[7,8]]) #Shape (2,2)\n",
    "\n",
    "print(\"\\nMatrix 1:\\n\", matrix1)\n",
    "print(\"\\nMatrix 2:\\n\", matrix2)\n",
    "\n",
    "# Using the @ operator (preferred for matrix multiplication)\n",
    "\n",
    "matrix_mult_res= matrix1 @ matrix2\n",
    "print(\"Matrix Multiplication (matrix1 @ matrix2):\\n\", matrix_mult_res)\n",
    "\n",
    "#using torch.matmul()\n",
    "matrix_mult_res_func=torch.matmul(matrix1, matrix2)\n",
    "print(\"Matrix Multiplication (torch.matmul(matrix1, matrix2):\\n\",matrix_mult_res_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e907250-1ed8-4285-96d6-aa5be45fc16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original 1D tensor (0-8):\n",
      " tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "Reshaped to 3x3:\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Reshaping Tensors\n",
    "original_tensor= torch.arange(9) #creates a 1D tensor from 0 to 8\n",
    "print(\"\\nOriginal 1D tensor (0-8):\\n\", original_tensor)\n",
    "\n",
    "#Reshape to a 3x3 matrix\n",
    "reshaped_3x3 =original_tensor.reshape(3,3)\n",
    "print(\"Reshaped to 3x3:\\n\", reshaped_3x3)\n",
    "original_tensor[0]=99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "614ffeb4-a89f-4328-9348-2865f80b9a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped using .view(3,3):\n",
      " tensor([[99,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8]])\n",
      "Flattened 3x3 tensor:\n",
      " tensor([99,  1,  2,  3,  4,  5,  6,  7,  8])\n"
     ]
    }
   ],
   "source": [
    "#Reshape using .view() -often shares memory with original\n",
    "reshape_view= original_tensor.view(3,3)\n",
    "print(\"Reshaped using .view(3,3):\\n\", reshape_view)\n",
    "# Note: If you change original_tensor, reshaped_view might change too if they share memory.\n",
    "# For a copy, use .clone()\n",
    "\n",
    "# Flatten a tensor (eg, for input to a linear layer)\n",
    "flattened_tensor = reshaped_3x3.view(-1) # -1 infers the size of that dimension\n",
    "print(\"Flattened 3x3 tensor:\\n\", flattened_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5794b818-f1f0-4b1a-a22d-6f28d743b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Data Tensor:\n",
      " tensor([[ 10,  20,  30,  40],\n",
      "        [ 50,  60,  70,  80],\n",
      "        [ 90, 100, 110, 120]])\n",
      "Element at (0,1): tensor(20)\n",
      "First Row: tensor([10, 20, 30, 40])\n",
      "Second Column: tensor([ 20,  60, 100])\n",
      "Sub-matrix (rows 0-1, cols 2-3):\n",
      " tensor([[30, 40],\n",
      "        [70, 80]])\n",
      "Specific elements (0,0) and (2,3): tensor([ 10, 120])\n"
     ]
    }
   ],
   "source": [
    "#4. Indexing and Slicing Tensors (Just like Numpy!)\n",
    "data_tensor = torch.tensor([[10, 20, 30, 40],\n",
    "                            [50, 60, 70, 80],\n",
    "                            [90, 100, 110, 120]])\n",
    "print(\"\\nOriginal Data Tensor:\\n\", data_tensor)\n",
    "# Access a single element (row 0, column 1)\n",
    "element = data_tensor[0,1]\n",
    "print(\"Element at (0,1):\", element)\n",
    "\n",
    "# Slice the first row (all columns)\n",
    "first_row = data_tensor[0, :]\n",
    "print(\"First Row:\", first_row)\n",
    "\n",
    "# Slice the second column (all rows)\n",
    "second_column = data_tensor[:, 1]\n",
    "print(\"Second Column:\", second_column)\n",
    "\n",
    "# Slice a sub-matrix (rows 0 to 1, columns 2 to 3)\n",
    "sub_matrix = data_tensor[0:2, 2:4]\n",
    "print(\"Sub-matrix (rows 0-1, cols 2-3):\\n\", sub_matrix)\n",
    "\n",
    "# Using integer indexing (select specific rows/columns)\n",
    "specific_elements = data_tensor[[0, 2], [0, 3]] # Element at (0,0) and (2,3)\n",
    "print(\"Specific elements (0,0) and (2,3):\", specific_elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcb97975-9384-47f1-b54b-4fe204ce9725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1094,  0.5996],\n",
      "        [-0.3362,  0.0879],\n",
      "        [-1.5134,  0.6372],\n",
      "        [-0.7322,  0.8461]]) torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "#mini exercise\n",
    "arr1=torch.randn(4,3)\n",
    "arr2= torch.randn(3,2)\n",
    "mul=arr1@arr2\n",
    "print(mul, mul.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6f572-8f26-4d30-acb4-1da8e086276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU vs. GPU (Device Management)\n",
    "#Neural networks involve a massive amount of numerical computation, especially matrix multiplications. While CPUs can handle these, GPUs (Graphics Processing Units) are specifically designed for parallel processing of large arrays of data and can perform these computations many times faster than CPUs.\n",
    "\n",
    "#CPU (Central Processing Unit): Your computer's main processor. Good for general-purpose tasks and sequential operations.\n",
    "#GPU (Graphics Processing Unit): A specialized processor optimized for parallel computation. Essential for accelerating deep learning training, especially on large datasets. NVIDIA GPUs are typically used with CUDA.\n",
    "#PyTorch allows you to easily move tensors and models between your CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c85dc9b-6e8b-4e59-9fc1-6741e8f374bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Device Management (CPU vs GPU)--\n",
      "\n",
      "GPU (CUDA) is NOT avaiable. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"--Device Management (CPU vs GPU)--\")\n",
    "\n",
    "#1. Check if GPU is avaiable (CUDA)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"\\nGPU (CUDA) is avaiable. Using GPU!\")\n",
    "else:\n",
    "    device=torch.device(\"cpu\")\n",
    "    print(\"\\nGPU (CUDA) is NOT avaiable. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f37ef325-35a5-4d16-9330-349ad61f2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor on CPU: tensor([1, 2, 3])\n",
      "Device of cpu_tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "#2. Create a tensor on CPU (default)\n",
    "cpu_tensor=torch.tensor([1,2,3])\n",
    "print(\"\\nTensor on CPU:\", cpu_tensor)\n",
    "print(\"Device of cpu_tensor:\",cpu_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5c9f3a5-ff59-467e-bfce-4431ac267ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor moved to device: tensor([1, 2, 3])\n",
      "Device of tensor_on_device: cpu\n"
     ]
    }
   ],
   "source": [
    "#3. Move the tensor to the determined device (GPU if avaiable, else stay on CPU)\n",
    "# .to(device) moves the tensor. It returns a NEW tensor on the target device.\n",
    "# It does NOT modify the tensor in-place.\n",
    "tensor_on_device = cpu_tensor.to(device)\n",
    "print(\"\\n Tensor moved to device:\",tensor_on_device)\n",
    "print(\"Device of tensor_on_device:\", tensor_on_device.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5e8d330-e269-43e1-bbc7-163c42975c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cannot create tensor directly on GPU, as GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "#4. Create a tensor directly on the GPU (if avaiable)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor_direct= torch.tensor([4,5,6], device=device)\n",
    "    print(\"\\nTensor created directly on GPU:\", gpu_tensor_direct)\n",
    "    print(\"Device of gpu_tensor_direct:\", gpu_tensor_direct.device)\n",
    "else:\n",
    "    print(\"\\nCannot create tensor directly on GPU, as GPU is not available.\")\n",
    "\n",
    "# Important Note: You cannot perform operations directly between tensors on different devices.\n",
    "# They must be on the same device.\n",
    "# Example: If cpu_tensor is on CPU and gpu_tensor_direct is on GPU, you CANNOT do cpu_tensor + gpu_tensor_direct.\n",
    "# You would need to move one to the other's device first:\n",
    "# result = cpu_tensor.to(device) + tensor_on_device  # Both are now on the same device\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a9fb0e2-c766-4fda-811d-6cb68b69f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial my_data (on CPU):\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Initial device: cpu\n",
      "\n",
      " No GPU avaiable so tensor remains on cpu\n"
     ]
    }
   ],
   "source": [
    "#mini Exercise\n",
    "#1. Create a 2x2 tensor 'my_data', filled with ones on the CPU.\n",
    "#2. If a GPU is available, move my_data to the GPU. Otherwise, ensure it remains on the CPU.\n",
    "#3. Print my_data and confirm its device.\n",
    "\n",
    "import torch\n",
    "\n",
    "my_data=torch.ones(2,2)\n",
    "print(\"Initial my_data (on CPU):\")\n",
    "print(my_data)\n",
    "print(\"Initial device:\", my_data.device)\n",
    "\n",
    "#Determine the device to use (GPU if available, else CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    print(\"\\nGPU (CUDA) is available. Moving tensor to GPU.\")\n",
    "    my_data=my_data.to(device)\n",
    "else:\n",
    "    device=torch.device(\"cpu\")\n",
    "    print(\"\\n No GPU avaiable so tensor remains on cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cb195-943e-46db-bc6a-7b41f3a79cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
